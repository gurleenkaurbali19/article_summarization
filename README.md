# ğŸ“° Article Summarization using NLP and Seq2Seq

This project implements an **abstractive text summarization system** using a **Sequence-to-Sequence (Seq2Seq)** model with **LSTM-based encoder-decoder architecture**. The model processes full-length news articles and generates concise, meaningful summaries using **deep learning** and **NLP techniques**.

---

## ğŸ” Project Highlights

- ğŸ“š Preprocessed a dataset of 4500+ news articles with metadata like authors, headlines, and full text
- ğŸ§¹ Applied tokenization, lemmatization, stopword removal, and padding
- ğŸ¤– Built a custom Seq2Seq model using **LSTM encoder-decoder architecture**
- ğŸš€ Trained on **Google Colab GPU** for faster execution
- ğŸ§  Fine-tuned with early stopping and custom loss functions
- ğŸ¤— Explored integration with Hugging Face Transformers for future scalability

---

## ğŸ§° Tech Stack

- **Language**: Python  
- **Libraries**: NLTK, NumPy, Pandas, TensorFlow, Keras, Matplotlib  
- **Environment**: Google Colab (GPU)  
- **Model Architecture**: Encoder-Decoder LSTM with Attention (optional upgrade)

---


