# 📰 Article Summarization using NLP and Seq2Seq

This project implements an **abstractive text summarization system** using a **Sequence-to-Sequence (Seq2Seq)** model with **LSTM-based encoder-decoder architecture**. The model processes full-length news articles and generates concise, meaningful summaries using **deep learning** and **NLP techniques**.

---

## 🔍 Project Highlights

- 📚 Preprocessed a dataset of 4500+ news articles with metadata like authors, headlines, and full text
- 🧹 Applied tokenization, lemmatization, stopword removal, and padding
- 🤖 Built a custom Seq2Seq model using **LSTM encoder-decoder architecture**
- 🚀 Trained on **Google Colab GPU** for faster execution
- 🧠 Fine-tuned with early stopping and custom loss functions
- 🤗 Explored integration with Hugging Face Transformers for future scalability

---

## 🧰 Tech Stack

- **Language**: Python  
- **Libraries**: NLTK, NumPy, Pandas, TensorFlow, Keras, Matplotlib  
- **Environment**: Google Colab (GPU)  
- **Model Architecture**: Encoder-Decoder LSTM with Attention (optional upgrade)

---


