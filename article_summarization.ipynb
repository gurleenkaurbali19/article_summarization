{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bc6472c-cccc-4c4d-9bb2-8bdd8e06d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67a8c4a0-59b3-47e8-8e1c-30dfa271e2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"news_summary.csv\", encoding='latin1')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9d330a7-4179-4ea5-af54-6cc0df4316df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>headlines</th>\n",
       "      <th>read_more</th>\n",
       "      <th>text</th>\n",
       "      <th>ctext</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chhavi Tyagi</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Daman &amp; Diu revokes mandatory Rakshabandhan in...</td>\n",
       "      <td>http://www.hindustantimes.com/india-news/raksh...</td>\n",
       "      <td>The Administration of Union Territory Daman an...</td>\n",
       "      <td>The Daman and Diu administration on Wednesday ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Daisy Mowke</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Malaika slams user who trolled her for 'divorc...</td>\n",
       "      <td>http://www.hindustantimes.com/bollywood/malaik...</td>\n",
       "      <td>Malaika Arora slammed an Instagram user who tr...</td>\n",
       "      <td>From her special numbers to TV?appearances, Bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arshiya Chopra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>'Virgin' now corrected to 'Unmarried' in IGIMS...</td>\n",
       "      <td>http://www.hindustantimes.com/patna/bihar-igim...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "      <td>The Indira Gandhi Institute of Medical Science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sumedha Sehra</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Aaj aapne pakad liya: LeT man Dujana before be...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/abu-dujana-...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "      <td>Lashkar-e-Taiba's Kashmir commander Abu Dujana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aarushi Maheshwari</td>\n",
       "      <td>03 Aug 2017,Thursday</td>\n",
       "      <td>Hotel staff to get training to spot signs of s...</td>\n",
       "      <td>http://indiatoday.intoday.in/story/sex-traffic...</td>\n",
       "      <td>Hotels in Maharashtra will train their staff t...</td>\n",
       "      <td>Hotels in Mumbai and other Indian cities are t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               author                  date  \\\n",
       "0        Chhavi Tyagi  03 Aug 2017,Thursday   \n",
       "1         Daisy Mowke  03 Aug 2017,Thursday   \n",
       "2      Arshiya Chopra  03 Aug 2017,Thursday   \n",
       "3       Sumedha Sehra  03 Aug 2017,Thursday   \n",
       "4  Aarushi Maheshwari  03 Aug 2017,Thursday   \n",
       "\n",
       "                                           headlines  \\\n",
       "0  Daman & Diu revokes mandatory Rakshabandhan in...   \n",
       "1  Malaika slams user who trolled her for 'divorc...   \n",
       "2  'Virgin' now corrected to 'Unmarried' in IGIMS...   \n",
       "3  Aaj aapne pakad liya: LeT man Dujana before be...   \n",
       "4  Hotel staff to get training to spot signs of s...   \n",
       "\n",
       "                                           read_more  \\\n",
       "0  http://www.hindustantimes.com/india-news/raksh...   \n",
       "1  http://www.hindustantimes.com/bollywood/malaik...   \n",
       "2  http://www.hindustantimes.com/patna/bihar-igim...   \n",
       "3  http://indiatoday.intoday.in/story/abu-dujana-...   \n",
       "4  http://indiatoday.intoday.in/story/sex-traffic...   \n",
       "\n",
       "                                                text  \\\n",
       "0  The Administration of Union Territory Daman an...   \n",
       "1  Malaika Arora slammed an Instagram user who tr...   \n",
       "2  The Indira Gandhi Institute of Medical Science...   \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...   \n",
       "4  Hotels in Maharashtra will train their staff t...   \n",
       "\n",
       "                                               ctext  \n",
       "0  The Daman and Diu administration on Wednesday ...  \n",
       "1  From her special numbers to TV?appearances, Bo...  \n",
       "2  The Indira Gandhi Institute of Medical Science...  \n",
       "3  Lashkar-e-Taiba's Kashmir commander Abu Dujana...  \n",
       "4  Hotels in Mumbai and other Indian cities are t...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f281ce9-f5db-4009-a551-4623550c1c51",
   "metadata": {},
   "source": [
    "#### columns in the dataset\n",
    "author: Name of the author.\n",
    "\n",
    "date: Date of publication.\n",
    "\n",
    "headlines: Headline of the news article. \n",
    "\n",
    "read_more: URL link for further reading.\n",
    "\n",
    "text: Summarized version of the article.\n",
    "\n",
    "ctext: Complete article text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57c36df0-d27c-4077-bcb2-061ab913b54d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author         0\n",
       "date           0\n",
       "headlines      0\n",
       "read_more      0\n",
       "text           0\n",
       "ctext        118\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "073d8514-115d-4ca2-9e36-96f8c6dcdcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ctext'] = data['ctext'].fillna(\"No content available\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "04701a09-6b1f-48b7-bef9-876f3d045c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author       0\n",
       "date         0\n",
       "headlines    0\n",
       "read_more    0\n",
       "text         0\n",
       "ctext        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d5500790-7d6e-4f5e-bfcd-81c79d34ab4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc76cf05-865d-42e8-be1b-42b0f7ebdccb",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9399dc80-45cb-4377-aeb6-eaa2880c569b",
   "metadata": {},
   "source": [
    "### Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "567b8df3-5f68-44c8-94c2-37eb927734c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               ctext  \\\n",
      "0  the daman and diu administration on wednesday ...   \n",
      "1  from her special numbers to tvappearances boll...   \n",
      "2  the indira gandhi institute of medical science...   \n",
      "3  lashkaretaibas kashmir commander abu dujana wa...   \n",
      "4  hotels in mumbai and other indian cities are t...   \n",
      "\n",
      "                                                text  \n",
      "0  the administration of union territory daman an...  \n",
      "1  malaika arora slammed an instagram user who tr...  \n",
      "2  the indira gandhi institute of medical science...  \n",
      "3  lashkaretaibas kashmir commander abu dujana wh...  \n",
      "4  hotels in maharashtra will train their staff t...  \n"
     ]
    }
   ],
   "source": [
    "# Function to clean text\n",
    "def clean_text(text):\n",
    "    # Remove non-alphabetic characters (e.g., punctuation, digits)\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove extra spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# Apply text cleaning on 'ctext' (complete article) and 'text' (summary)\n",
    "data['ctext'] = data['ctext'].apply(clean_text)\n",
    "data['text'] = data['text'].apply(clean_text)\n",
    "\n",
    "# Verify cleaning\n",
    "print(data[['ctext', 'text']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7803c13-2b1b-420d-afcb-631eef40fca4",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "91639680-6b86-4a8e-996e-1a4a33f1fee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# Loading spaCy's English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Function to tokenize using spaCy\n",
    "def spacy_tokenizer(text):\n",
    "    doc = nlp(text)\n",
    "    return [token.text for token in doc]\n",
    "\n",
    "# Apply tokenization to the data\n",
    "data['ctext_tokens'] = data['ctext'].apply(spacy_tokenizer)\n",
    "data['text_tokens'] = data['text'].apply(spacy_tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "353b56e6-35a3-4300-92ee-a6c77b26dfde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    the daman and diu administration on wednesday ...\n",
      "1    from her special numbers to tvappearances boll...\n",
      "2    the indira gandhi institute of medical science...\n",
      "3    lashkaretaibas kashmir commander abu dujana wa...\n",
      "4    hotels in mumbai and other indian cities are t...\n",
      "Name: ctext, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['ctext'].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c3847c-90d7-4270-b786-3536bb5e67a2",
   "metadata": {},
   "source": [
    "### Lowercasing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49acf9ce-3b01-49e0-a96e-d3a8c599a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting all text to lowercase to make the text consistent and reduce the size of the vocabulary.\n",
    "data['ctext'] = data['ctext'].str.lower()\n",
    "data['text'] = data['text'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b9d494-f2b8-4f7a-9cab-beb5149ee21a",
   "metadata": {},
   "source": [
    "### Handling Contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c2816a8-375d-4965-b921-571a4119fdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Contractions are shortened forms of words or phrases created by omitting certain\n",
    "#letters and replacing them with an apostrophe (') like cannot --> can't\n",
    "#Expanding contractions can be important for text preprocessing, especially for NLP tasks, \n",
    "#as it ensures consistency in the text and helps models understand the full form of words.\n",
    "import contractions\n",
    "#This imports the contractions library, which provides a fix() function to expand contractions in a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244b6fc5-a12d-4142-9e20-7be13d9e7271",
   "metadata": {},
   "source": [
    "##### \n",
    "The apply() method is used to apply a function to every element in the data['ctext'] column. \n",
    "\n",
    "\n",
    "The lambda function (lambda x: contractions.fix(x)) passes each string x from the column to the contractions.fix() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cddcff8f-8ccf-4ab8-a8bd-baeec94b0506",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ctext'] = data['ctext'].apply(lambda x: contractions.fix(x))\n",
    "data['text'] = data['text'].apply(lambda x: contractions.fix(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1150c4d-9e6d-4cd5-b106-7f5f35717b62",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdc6507-6b7a-4bc2-90cd-ef68e6836c64",
   "metadata": {},
   "source": [
    "##### Lemmatization is the process of reducing words to their base or root form (known as a lemma) while ensuring that the resulting word is valid in the language. \n",
    "why?\n",
    "\n",
    "+ Reduces Inflectional Variants: Words like running, runs, and ran are reduced to run, improving consistency in the dataset.\n",
    "\n",
    "+ Improves Model Performance: Helps in reducing dimensionality and improves the efficiency of machine learning or NLP models.\n",
    "\n",
    "+ Preserves Meaning: Unlike stemming, lemmatization ensures the root word is meaningful in the language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f34bebc3-d2c3-4114-973b-65d58474923b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "#The WordNetLemmatizer is part of the Natural Language Toolkit (nltk) library and is specifically\n",
    "#designed to perform lemmatization by leveraging the WordNet lexical database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c7b2b46-f60e-4021-a545-b3a23f140efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "#Creates an instance of the WordNetLemmatizer class, which provides the lemmatize() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d31959ca-4572-497f-bd56-aeea2e4df020",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1eb38c68-d88a-4baa-b636-230f534930d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ctext'] = data['ctext'].apply(lemmatize_text)\n",
    "data['text'] = data['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb007f32-9cff-4a80-8be6-fa45fa1561ff",
   "metadata": {},
   "source": [
    "### Truncation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7cdcafb-7f83-4229-a31c-b1ed8b3b1249",
   "metadata": {},
   "source": [
    "##### \n",
    "+ Truncation ensures that overly long sequences are cut down to a manageable size, reducing memory usage and improving training efficiency.\n",
    "+ Padding ensures that shorter sequences are extended to a fixed length, so they align with longer sequences during batch processing.\n",
    "\n",
    "For text summarization:\n",
    "\n",
    "+ Articles (input) might need a longer maximum sequence length (e.g., 512 tokens).\n",
    "+ Summaries (output) typically require shorter lengths (e.g., 128 tokens).\n",
    "+ Processing overly long texts can be computationally expensive.\n",
    "+ Limiting the length reduces memory and computation costs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773160f8-86be-4d35-8430-c1201c3ebe59",
   "metadata": {},
   "source": [
    "##### \n",
    "In text summarization tasks, input sequences (articles) and output sequences (summaries) often have varying lengths. Neural networks require inputs of uniform size, so truncation and padding are necessary preprocessing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7db647c4-8a4e-44b4-a9d3-13aaf5574b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the maximum lengths\n",
    "max_article_len = 512\n",
    "max_summary_len = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f6cab53c-3ac8-449c-bbc5-ed463e3caf04",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ctext'] = data['ctext'].apply(lambda x: \" \".join(x.split()[:max_article_len]))\n",
    "data['text'] = data['text'].apply(lambda x: \" \".join(x.split()[:max_summary_len]))\n",
    "#splitting the lines then only taking the specified number of words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4d07d-b7a3-4f76-a702-1c3e131f03a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3485f90a-3001-4c44-9ef4-39002c1de8b8",
   "metadata": {},
   "source": [
    "### Removing rare words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84949a82-5926-4930-a761-03ee689cc593",
   "metadata": {},
   "source": [
    "##### \n",
    "+ Rare words (those that appear only once) can often be unimportant for many NLP tasks, especially in text classification or topic modeling.\n",
    "+ Removing these words helps reduce the noise in the data and can improve model performance.\n",
    "+ By reducing the dimensionality (i.e., removing rare words), the size of the vocabulary decreases, which can speed up training and reduce overfitting.\n",
    "+ In some cases, rare words may be outliers or irrelevant for the analysis, so removing them can help focus on the more important and consistent terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9a9a5f11-69f5-4f22-8847-fef4a7cac394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Get word frequencies\n",
    "all_words = \" \".join(data['ctext']).split()\n",
    "word_freq = Counter(all_words)  #returns a dictionary of all words with their frequencies\n",
    "\n",
    "# Remove rare words\n",
    "rare_words = set(word for word, freq in word_freq.items() if freq == 1)\n",
    "data['ctext'] = data['ctext'].apply(lambda x: \" \".join(word for word in x.split() if word not in rare_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9937d043-1a72-4983-9f43-49b4cb1244a7",
   "metadata": {},
   "source": [
    "### Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596ab799-fa94-447d-9bbe-e843f3644108",
   "metadata": {},
   "source": [
    "##### \n",
    "+ Converting the cleaned text into numerical format that the model can understand.\n",
    "+ Essential because neural networks require inputs as numerical data. Text needs to be converted into sequences of integers where each integer represents a specific word or token in your vocabulary.\n",
    "+ Padding is the process of adding extra tokens (usually zero) to the end (or sometimes the beginning) of a sequence to make all sequences in the dataset have the same length. These padding tokens donâ€™t carry any meaningful information but are used solely to standardize the length of all sequences in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ae322a81-69ef-4a09-a119-b1de2adf3ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ed6489b1-da72-401e-8a14-60f1f7930668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the tokenizer\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# Fit the tokenizer on both articles (ctext) and summaries (text)\n",
    "tokenizer.fit_on_texts(data['ctext'].tolist() + data['text'].tolist())\n",
    "\n",
    "# Convert the texts to sequences of integers\n",
    "data['ctext_seq'] = tokenizer.texts_to_sequences(data['ctext'])\n",
    "data['text_seq'] = tokenizer.texts_to_sequences(data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "788f89ac-877a-4117-84fe-145522656961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the maximum lengths\n",
    "max_article_len = 512\n",
    "max_summary_len = 128\n",
    "\n",
    "# Apply padding to make all sequences the same length\n",
    "padded_ctext_seq = pad_sequences(data['ctext_seq'], maxlen=max_article_len, padding='post', truncating='post')\n",
    "padded_text_seq = pad_sequences(data['text_seq'], maxlen=max_summary_len, padding='post', truncating='post')\n",
    "\n",
    "# padded sequences for training\n",
    "data['padded_ctext_seq'] = list(padded_ctext_seq)\n",
    "data['padded_text_seq'] = list(padded_text_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588ffef5-97a2-4336-bad7-228a57714100",
   "metadata": {},
   "source": [
    "##### \n",
    "+ Tokenizer: This is a class from Keras' tensorflow.keras.preprocessing.text module. It's used to convert text into a sequence of integers. Each integer corresponds to a word in the dataset's vocabulary. The Tokenizer object will create a mapping between words and integers based on their frequency in the training data.\n",
    "+ fit_on_texts: This method is used to learn the word indices (integer mappings) from a list of texts.\n",
    "+  It processes all the words in both the ctext (articles) and text (summaries) columns, counting the frequency of each word. Words that appear more frequently will have a lower index, while rare words will have a higher index. The fit_on_texts method creates a word-to-integer mapping, called the word index.\n",
    "+  texts_to_sequences: This method converts each text (article or summary) into a sequence of integers based on the word-to-integer mapping learned earlier in the fit_on_texts() method.\n",
    "+  For each word in an article or summary, it replaces the word with its corresponding integer value from the vocabulary built by fit_on_texts().\n",
    "+  pad_sequences: This function ensures that all sequences (of articles and summaries) have the same length. It handles both truncation (shortening long sequences) and padding (extending short sequences).\n",
    "+  maxlen=max_article_len: Ensures the sequences are at most 512 words long (articles).\n",
    "maxlen=max_summary_len: Ensures the sequences are at most 128 words long (summaries).\n",
    "+ padding='post': This means that if the sequence is shorter than the desired length, zeros will be added at the end of the sequence. If padding='pre', zeros would be added at the beginning instead.\n",
    "truncating='post': If the sequence is longer than the desired length, it will be truncated (cut off) from the end. If truncating='pre', truncation would happen from the beginning.\n",
    "+ Padding and truncation ensure that all sequences have a uniform length. Deep learning models typically expect fixed-size inputs, and padding ensures that all sequences match the specified length.\n",
    "+ After applying padding and truncation, the padded sequences are stored in the DataFrame as data['padded_ctext_seq']\n",
    "(for articles) and data['padded_text_seq'] (for summaries).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa99fd2b-cb28-4488-9584-d1029c74ab01",
   "metadata": {},
   "source": [
    "##### Summary of the Workflow\n",
    "+ Text Tokenization: Convert the raw text (articles and summaries) into sequences of integers, where each integer represents a word.\n",
    "+ Padding and Truncation: Ensure that all sequences (both input articles and output summaries) have the same length by either truncating longer sequences or padding shorter ones.\n",
    "+ Preprocessing: Once the sequences are tokenized and padded, they are stored in the DataFrame for use in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8982dc-3505-4e72-9f01-2863ce1c3acf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
